{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "> Plugin metadata structures for tracking plugin information and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m3n4o5p6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Optional, List, Type\n",
    "\n",
    "from cjm_fasthtml_plugins.core.execution_mode import PluginExecutionMode, CloudProviderType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## Remote Resource Information\n",
    "\n",
    "For plugins that execute on remote/cloud resources, we track information about those resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class RemoteResourceInfo:\n",
    "    \"\"\"Information about a remote/cloud resource used by a plugin.\"\"\"\n",
    "    provider: CloudProviderType  # Cloud provider or service\n",
    "    region: Optional[str] = None  # Cloud region/zone\n",
    "    instance_id: Optional[str] = None  # VM/instance identifier\n",
    "    job_id: Optional[str] = None  # Job/task identifier on remote system\n",
    "    endpoint_url: Optional[str] = None  # HTTP endpoint for API access\n",
    "    ssh_host: Optional[str] = None  # SSH host for remote access\n",
    "    ssh_port: int = 22  # SSH port number\n",
    "    status: str = \"unknown\"  # Current status (provisioning, running, stopping, stopped)\n",
    "    resource_type: Optional[str] = None  # Instance type (e.g., 'p3.2xlarge', 'n1-standard-8')\n",
    "    gpu_count: int = 0  # Number of GPUs\n",
    "    gpu_type: Optional[str] = None  # GPU model (e.g., 'V100', 'A100', 'H100')\n",
    "    estimated_cost_per_hour: Optional[float] = None  # Estimated hourly cost in USD\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)  # Additional provider-specific metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: aws\n",
      "Instance: i-1234567890abcdef\n",
      "GPUs: 4x V100\n",
      "Cost: $12.24/hour\n"
     ]
    }
   ],
   "source": [
    "# Example: Create remote resource info for AWS instance\n",
    "aws_resource = RemoteResourceInfo(\n",
    "    provider=CloudProviderType.AWS,\n",
    "    region=\"us-west-2\",\n",
    "    instance_id=\"i-1234567890abcdef\",\n",
    "    resource_type=\"p3.8xlarge\",\n",
    "    gpu_count=4,\n",
    "    gpu_type=\"V100\",\n",
    "    status=\"running\",\n",
    "    estimated_cost_per_hour=12.24,\n",
    "    ssh_host=\"54.123.45.67\"\n",
    ")\n",
    "\n",
    "print(f\"Provider: {aws_resource.provider.value}\")\n",
    "print(f\"Instance: {aws_resource.instance_id}\")\n",
    "print(f\"GPUs: {aws_resource.gpu_count}x {aws_resource.gpu_type}\")\n",
    "print(f\"Cost: ${aws_resource.estimated_cost_per_hour}/hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: lambda_labs\n",
      "Status: provisioning\n",
      "Configuration: 4x_A100\n"
     ]
    }
   ],
   "source": [
    "# Example: Create remote resource info for Lambda Labs\n",
    "lambda_resource = RemoteResourceInfo(\n",
    "    provider=CloudProviderType.LAMBDA_LABS,\n",
    "    instance_id=\"0x1a2b3c4d\",\n",
    "    resource_type=\"4x_A100\",\n",
    "    gpu_count=4,\n",
    "    gpu_type=\"A100\",\n",
    "    status=\"provisioning\",\n",
    "    estimated_cost_per_hour=4.40,\n",
    "    region=\"us-west-1\"\n",
    ")\n",
    "\n",
    "print(f\"Provider: {lambda_resource.provider.value}\")\n",
    "print(f\"Status: {lambda_resource.status}\")\n",
    "print(f\"Configuration: {lambda_resource.resource_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3h4i5j6",
   "metadata": {},
   "source": [
    "## Plugin Metadata\n",
    "\n",
    "The main metadata structure that describes a plugin and tracks its runtime state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class PluginMetadata:\n",
    "    \"\"\"Metadata describing a plugin for display and resource management without loading the plugin instance.\"\"\"\n",
    "    name: str  # Internal plugin identifier\n",
    "    category: str  # Plugin category string (application-defined)\n",
    "    title: str  # Display title for the plugin\n",
    "    config_schema: Dict[str, Any]  # JSON Schema for plugin configuration (auto-generated from config_dataclass)\n",
    "    config_dataclass: Optional[Type] = None  # Configuration dataclass type (if available)\n",
    "    description: Optional[str] = None  # Plugin description\n",
    "    version: Optional[str] = None  # Plugin version\n",
    "    is_configured: bool = False  # Whether the plugin has saved configuration\n",
    "    \n",
    "    # Lifecycle metadata\n",
    "    execution_mode: PluginExecutionMode = PluginExecutionMode.IN_PROCESS  # How the plugin executes\n",
    "    manages_child_processes: bool = False  # Whether plugin spawns child processes\n",
    "    manages_external_resources: bool = False  # Whether plugin manages Docker/servers/etc.\n",
    "    \n",
    "    # Local resource tracking\n",
    "    spawned_pids: List[int] = field(default_factory=list)  # List of child process PIDs\n",
    "    container_id: Optional[str] = None  # Docker container ID if applicable\n",
    "    conda_env_name: Optional[str] = None  # Conda environment name if applicable\n",
    "    \n",
    "    # Cloud/Remote resource tracking\n",
    "    remote_resource: Optional[RemoteResourceInfo] = None  # Remote resource information if applicable\n",
    "    \n",
    "    def get_unique_id(self) -> str:  # String in format 'category_name'\n",
    "        \"\"\"Generate unique ID for this plugin.\"\"\"\n",
    "        return f\"{self.category}_{self.name}\"\n",
    "    \n",
    "    def is_local_execution(self) -> bool:  # True if execution is local\n",
    "        \"\"\"Check if plugin executes locally (not cloud/remote).\"\"\"\n",
    "        local_modes = {\n",
    "            PluginExecutionMode.IN_PROCESS,\n",
    "            PluginExecutionMode.SUBPROCESS,\n",
    "            PluginExecutionMode.DOCKER,\n",
    "            PluginExecutionMode.CONDA_ENV,\n",
    "            PluginExecutionMode.EXTERNAL_SERVICE\n",
    "        }\n",
    "        return self.execution_mode in local_modes\n",
    "    \n",
    "    def is_cloud_execution(self) -> bool:  # True if execution is cloud/remote\n",
    "        \"\"\"Check if plugin executes on cloud/remote resources.\"\"\"\n",
    "        return not self.is_local_execution()\n",
    "    \n",
    "    def has_active_resources(self) -> bool:  # True if plugin has child processes, containers, or cloud resources\n",
    "        \"\"\"Check if plugin has active managed resources.\"\"\"\n",
    "        return bool(\n",
    "            self.spawned_pids or\n",
    "            self.container_id or\n",
    "            (self.remote_resource and self.remote_resource.status == \"running\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o1p2q3r4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: Whisper Tiny Model\n",
      "Unique ID: transcription_whisper_tiny\n",
      "Execution mode: in_process\n",
      "Is local: True\n",
      "Has active resources: False\n"
     ]
    }
   ],
   "source": [
    "# Example: Create simple in-process plugin metadata\n",
    "simple_plugin = PluginMetadata(\n",
    "    name=\"whisper_tiny\",\n",
    "    category=\"transcription\",\n",
    "    title=\"Whisper Tiny Model\",\n",
    "    config_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"device\": {\"type\": \"string\", \"enum\": [\"cpu\", \"cuda\"], \"default\": \"cpu\"}\n",
    "        }\n",
    "    },\n",
    "    version=\"1.0.0\",\n",
    "    is_configured=True\n",
    ")\n",
    "\n",
    "print(f\"Plugin: {simple_plugin.title}\")\n",
    "print(f\"Unique ID: {simple_plugin.get_unique_id()}\")\n",
    "print(f\"Execution mode: {simple_plugin.execution_mode.value}\")\n",
    "print(f\"Is local: {simple_plugin.is_local_execution()}\")\n",
    "print(f\"Has active resources: {simple_plugin.has_active_resources()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5t6u7v8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: Voxtral via vLLM Server\n",
      "Execution mode: subprocess\n",
      "Manages child processes: True\n",
      "Spawned PIDs: [54321, 54322, 54323]\n",
      "Has active resources: True\n"
     ]
    }
   ],
   "source": [
    "# Example: Create plugin with subprocess (vLLM-style)\n",
    "vllm_plugin = PluginMetadata(\n",
    "    name=\"voxtral_vllm\",\n",
    "    category=\"transcription\",\n",
    "    title=\"Voxtral via vLLM Server\",\n",
    "    config_schema={\"type\": \"object\", \"properties\": {}},\n",
    "    execution_mode=PluginExecutionMode.SUBPROCESS,\n",
    "    manages_child_processes=True,\n",
    "    manages_external_resources=True,\n",
    "    spawned_pids=[54321, 54322, 54323]\n",
    ")\n",
    "\n",
    "print(f\"Plugin: {vllm_plugin.title}\")\n",
    "print(f\"Execution mode: {vllm_plugin.execution_mode.value}\")\n",
    "print(f\"Manages child processes: {vllm_plugin.manages_child_processes}\")\n",
    "print(f\"Spawned PIDs: {vllm_plugin.spawned_pids}\")\n",
    "print(f\"Has active resources: {vllm_plugin.has_active_resources()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w9x0y1z2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: AWS LLM Finetuning\n",
      "Execution mode: cloud_gpu\n",
      "Is cloud: True\n",
      "Provider: aws\n",
      "Instance: i-abcd1234\n",
      "Cost: $24.5/hour\n",
      "Has active resources: True\n"
     ]
    }
   ],
   "source": [
    "# Example: Create cloud-based plugin\n",
    "cloud_plugin = PluginMetadata(\n",
    "    name=\"llm_finetune_aws\",\n",
    "    category=\"finetuning\",\n",
    "    title=\"AWS LLM Finetuning\",\n",
    "    config_schema={\"type\": \"object\", \"properties\": {}},\n",
    "    execution_mode=PluginExecutionMode.CLOUD_GPU,\n",
    "    manages_external_resources=True,\n",
    "    remote_resource=RemoteResourceInfo(\n",
    "        provider=CloudProviderType.AWS,\n",
    "        instance_id=\"i-abcd1234\",\n",
    "        status=\"running\",\n",
    "        gpu_count=8,\n",
    "        gpu_type=\"A100\",\n",
    "        estimated_cost_per_hour=24.50\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Plugin: {cloud_plugin.title}\")\n",
    "print(f\"Execution mode: {cloud_plugin.execution_mode.value}\")\n",
    "print(f\"Is cloud: {cloud_plugin.is_cloud_execution()}\")\n",
    "print(f\"Provider: {cloud_plugin.remote_resource.provider.value}\")\n",
    "print(f\"Instance: {cloud_plugin.remote_resource.instance_id}\")\n",
    "print(f\"Cost: ${cloud_plugin.remote_resource.estimated_cost_per_hour}/hour\")\n",
    "print(f\"Has active resources: {cloud_plugin.has_active_resources()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i1j2k3l4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
